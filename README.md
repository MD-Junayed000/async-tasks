# Async Task Processing System with Flask, Celery, RabbitMQ & Pulumi-Driven AWS Deployment

This project demonstrates a production-ready asynchronous task processing system (i.e Deployed in EC2 using Pulumi explained in infra-branch) using:

* âœ… Flask (Web + API)
* âœ… Celery (Task Queue Executor)
* âœ… RabbitMQ (Message Broker)
* âœ… Redis (Result Backend)
* âœ… Flower (Monitoring UI)
* âœ… Docker (Multi-service orchestration)

>  **Objective**: Design a system that allows users to submit tasks asynchronously from a Flask API, execute them reliably in the background using Celery, queue tasks in RabbitMQ, and store task states and results in a backend db (redis).

---

##  System Architecture :
<img src="assets/implement.svg" alt="Implementation Diagram" width="1000">

***1. User Request via API :***

â†’ Sends request from UI (email, text reverse, sentiment).

***2. Flask App :***

â†’ Receives request and pushes task to Celery using delay()

â†’ Immediately responds to user (non-blocking).

***3. Celery Producer Role (ğŸ“© Task Sent to Broker):***

â†’  When .delay() is called in Flask,  celery sends the task to RabbitMQ (the message broker).

â†’ So, Flask acts as the Producer in this diagram.

***4. RabbitMQ Queue (Message Broker):***

â†’ Holds tasks in queue(s).

â†’ Forwards them to Celery Worker.

***5. Celery Workers:***

â†’ Continuously listens to RabbitMQ.

â†’ Pulls and executes tasks (email/text/sentiment).

â†’ Can run multiple processes (parallel).



***6. Redis (Result Backend):***

â†’ Stores task result/status (e.g., SUCCESS, FAILURE).

â†’ Flask can query result using ***AsyncResult.***

***7. UI Feedback:***

â†’ Task ID flashed in UI.

â†’ Success/failure notification shown based on result from Redis.

---
## Project Features :
* ğŸ“¨ Async Email Sender with retry logic

* ğŸ” Reverse Text Processor * ğŸ’¬ Fake Sentiment Analyzer

* ğŸ” Redis-based task result storage

* ğŸ“Š Live task monitoring via Flower

* ğŸ§ª Task inspection via Redis

* ğŸ–¥ï¸ UI with feedback using Flask + Bootstrap

* ğŸ³ Docker-based deployment


### ğŸ”§ Components :

| Component    | Role                                 |
| ------------ | ------------------------------------ |
| **Flask**    | UI, task submission, status fetch    |
| **Celery**   | Task execution engine                |
| **RabbitMQ** | Message broker to queue tasks        |
| **Redis**    | Stores task status & results         |
| **Flower**   | Real-time task monitoring dashboard  |
| **Docker**   | Container orchestration for services |




###  Queues and Exchange in RabbitMQ

<img src="assets/Broker.svg" alt="Broker Diagram" width="700">

* Celery uses a direct exchange

* Tasks routed by name â†’ bound to celery_see queue

* Each worker listens on that queue

>> In RabbitMQ:

* Producer = Flask (via Celery)

* Consumer = Celery Worker

* Exchange = Implicit direct exchange

* Queue = celery_see (task queue)





## ğŸ“ Project Structure

```
async-tasks/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py          # Flask app factory
â”‚   â”œâ”€â”€ celeryconfig.py      # Celery broker/backend configs
â”‚   â”œâ”€â”€ routes.py            # Routes for UI + task handling
â”‚   â”œâ”€â”€ tasks.py             # Celery tasks
â”‚   â”œâ”€â”€ templates/           # Jinja2 HTML UI (index.html)
â”‚   â””â”€â”€ static/              # CSS, images, icons
â”‚
â”œâ”€â”€ Dockerfile               # Docker image setup
â”œâ”€â”€ docker-compose.yml       # Multi-service Docker config
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ run.py                   # Flask run entry
â”œâ”€â”€ start.sh / start.ps1     # Quick Docker starter script

```

---



---

## Step-by-Step Setup

### 1ï¸âƒ£ Clone the Repo and Navigate

```bash
git clone https://github.com/your-username/async-tasks.git
cd async-tasks
```

### 2ï¸âƒ£ Create & Activate Python Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate   # Windows
# OR
source venv/bin/activate  # Linux/macOS
```

### 3ï¸âƒ£ Install Required Packages

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Start Services via Docker

```bash
docker-compose up --build
```



## ğŸŒ URLs & Ports

| Service        | URL                                              |
| -------------- | ------------------------------------------------ |
| Flask UI       | [http://localhost:5000](http://localhost:5000)   |
| RabbitMQ Admin | [http://localhost:15672](http://localhost:15672) |
| Flower Monitor | [http://localhost:5555](http://localhost:5555)   |



##  Available Tasks

| Task Type        | Description                           |
| ---------------- | ------------------------------------- |
| **Send Email**   | Simulates sending an email (w/ retry) |
| **Reverse Text** | Reverses any string                   |
| **Sentiment**    | Fake sentiment analysis on input text |

Each task returns a `Task ID` and status message âœ…/âŒ.

---
## Error Handling & Retries
>Email task uses self.retry() with max_retries=3

>If task fails, it's requeued

>Redis tracks the task state:

*PENDING, SUCCESS, RETRY, FAILURE

> inspect it using:

```bash
docker exec -it redis redis-cli
> KEYS *
```




##  Task Monitoring with Flower

* Open [http://localhost:5555](http://localhost:5555)
* View task history, retries, failures
* Inspect live workers and system load



##  Task Status API

### ğŸ” GET `/check_status/<task_id>`

Returns task status from Redis:

```json
{
  "task_id": "a1b2c3d4",
  "state": "SUCCESS",
  "result": "Email sent to xyz"
}
```

### ğŸ§ª Use Postman for Submissions

Example JSON for email:

```json
{
  "form_type": "email",
  "recipient": "someone@example.com",
  "subject": "Greetings",
  "body": "Hello from Flask"
}
```

---
## âš ï¸ Common Issues & Fixes

| Problem                 | Fix                                    |
| ----------------------- | -------------------------------------- |
| Task not completing     | Check RabbitMQ & Celery logs           |
| Task stuck in `PENDING` | Check Redis config or broker queue     |
| No Redis output         | Use `AsyncResult().get()` or API fetch |
| UI not showing output   | Ensure sessions are set up correctly   |

---

##  Deployment on AWS EC2 (Fully Explained in --branch infra)

1. Launch Ubuntu EC2
2. SSH into it
3.Run docker-compose up
4.Expose ports 5000, 5672, 6379, 15672, 5555 in security group



##  Concepts Implemented

* âœ… Direct exchange with `celery_see` queue
* âœ… Multi-worker concurrency with `--concurrency=4`
* âœ… Flask session flash for notifications
* âœ… Redis result tracking via `AsyncResult`
* âœ… Queue retry using `self.retry()`





## License

MIT License Â© 2025 [poridhi.io](https://poridhi.io)
